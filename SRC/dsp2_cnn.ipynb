{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gxte0yYk5Uop"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVo846TM5M5r"
      },
      "outputs": [],
      "source": [
        "# Run this code if in google colab\n",
        "# Input archive zip file is named images.zip in folder\n",
        "if not os.path.isdir('test'):\n",
        "    !unzip 'images.zip'\n",
        "    shutil.rmtree('train/disgust')\n",
        "    shutil.rmtree('test/disgust')\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6MXJvJwbyYCR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Rescaling, BatchNormalization\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.utils import image_dataset_from_directory\n",
        "from keras.regularizers import L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Cwao6_Eavhw0"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    'batch_size' : 32,\n",
        "    'image_size' : (64,64),\n",
        "    'input_shape' : (64,64,1),\n",
        "    'validation_split': 0.2,\n",
        "    'epoch': 75,\n",
        "    'learning_rate' : 0.001\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n76d6Nq61fpX"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    \n",
        "    def plot(train, val, kind):\n",
        "\n",
        "        x = np.arange(1, np.size(train) + 1)\n",
        "\n",
        "        plt.plot(x, train, label = \"training \" + kind)\n",
        "        plt.plot(x, val, label = \"validation \" + kind)\n",
        "        plt.xlabel(\"epoch\")\n",
        "        plt.ylabel(kind)\n",
        "        plt.title(\"training and validation \" + kind + \" v epoch\")\n",
        "        plt.show()\n",
        "        \n",
        "    train_loss_history = history.history['loss']\n",
        "    val_loss_history = history.history['val_loss']\n",
        "\n",
        "    train_acc_history = history.history['accuracy']\n",
        "    val_acc_history = history.history['val_accuracy']\n",
        "\n",
        "    # plot\n",
        "    plot(train_loss_history, val_loss_history, 'loss')\n",
        "    plot(train_acc_history, val_acc_history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YFbdho3Hrmx2"
      },
      "outputs": [],
      "source": [
        "def create_cnn(args=None):\n",
        "\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Rescaling(1./255))\n",
        " \n",
        "\tmodel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\tmodel.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\tmodel.add(Dropout(0.4))\n",
        "\n",
        "\tmodel.add(Flatten())\n",
        "\n",
        "\tmodel.add(Dense(units = 512, activation = 'relu'))\n",
        "\tmodel.add(Dropout(0.6))\n",
        "\tmodel.add(Dense(units = 6, activation = 'softmax'))\n",
        "\n",
        "    # Compile\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ieOvGfVEkouV"
      },
      "outputs": [],
      "source": [
        "def train_cnn(directory, args=None):\n",
        "\t# You can use args to pass parameter values to this method\n",
        "    train, valid = tf.keras.utils.image_dataset_from_directory(\n",
        "        directory, label_mode = 'categorical', color_mode = 'grayscale',\n",
        "        image_size = args['image_size'], seed = 0, batch_size = args['batch_size'],\n",
        "        validation_split = args['validation_split'], subset = 'both')\n",
        "    \n",
        "    model = create_cnn(args)\n",
        "    history = model.fit(train, epochs = args['epoch'], \n",
        "                        validation_data = valid)\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z_W1e9pbxNJv"
      },
      "outputs": [],
      "source": [
        "def analyze_model(test, model, history):\n",
        "\n",
        "    print(model.summary())\n",
        "    print('------------------------------------------------------------------')\n",
        "    plot_history(history)\n",
        "    print('------------------------------------------------------------------')\n",
        "    \n",
        "    test_data = tf.keras.utils.image_dataset_from_directory(\n",
        "        test, label_mode = 'categorical', color_mode = 'grayscale', \n",
        "        image_size = args['image_size'], batch_size = args['batch_size'])\n",
        "\n",
        "    labels = sorted(os.listdir('test'))\n",
        "    predicted = [labels[label] for label in \\\n",
        "                 np.argmax(cnn_model.predict(test_data), axis = 1)]\n",
        "    actual = [labels[label] for label in \\\n",
        "                np.argmax(np.concatenate([y for x, y in test_data], axis=0),axis = 1)]\n",
        "    test_df = pd.DataFrame({'Actual Label':actual,'Predicted Label':predicted})\n",
        "    test_df['Prediction Correct'] = test_df['Actual Label'] == test_df['Predicted Label']\n",
        "\n",
        "    prediction_accuracy = test_df['Prediction Correct'].mean()\n",
        "    print('Prediction Accuracy of Model: ', prediction_accuracy)\n",
        "\n",
        "    display(test_df)\n",
        "    print('------------------------------------------------------------------')\n",
        "\n",
        "    def plot(srs, x, y, title):\n",
        "        plt.bar(srs.index, srs)\n",
        "        plt.xlabel(x)\n",
        "        plt.ylabel(y)\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "    \n",
        "    prediction_by_label = test_df.groupby('Predicted Label')['Prediction Correct'].mean()\n",
        "    display(prediction_by_label)\n",
        "    \n",
        "    plot(prediction_by_label, 'Label', 'Prediction Accuracy', \n",
        "         'Prediction Accuracy by Label')\n",
        "    print('------------------------------------------------------------------')\n",
        "    print('------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU80GLHGvD8i",
        "outputId": "06d9ae5b-e69e-489a-c592-8410e3a95479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 28273 files belonging to 6 classes.\n",
            "Using 22619 files for training.\n",
            "Using 5654 files for validation.\n",
            "Epoch 1/75\n",
            "707/707 [==============================] - 11s 12ms/step - loss: 1.7130 - accuracy: 0.2791 - val_loss: 1.6045 - val_accuracy: 0.3513\n",
            "Epoch 2/75\n",
            "707/707 [==============================] - 8s 12ms/step - loss: 1.5602 - accuracy: 0.3718 - val_loss: 1.4638 - val_accuracy: 0.4294\n",
            "Epoch 3/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.4506 - accuracy: 0.4276 - val_loss: 1.3729 - val_accuracy: 0.4613\n",
            "Epoch 4/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.3875 - accuracy: 0.4491 - val_loss: 1.3371 - val_accuracy: 0.4767\n",
            "Epoch 5/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.3480 - accuracy: 0.4725 - val_loss: 1.3156 - val_accuracy: 0.4818\n",
            "Epoch 6/75\n",
            "707/707 [==============================] - 9s 12ms/step - loss: 1.3127 - accuracy: 0.4887 - val_loss: 1.2809 - val_accuracy: 0.5004\n",
            "Epoch 7/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.2807 - accuracy: 0.5035 - val_loss: 1.2548 - val_accuracy: 0.5097\n",
            "Epoch 8/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.2589 - accuracy: 0.5132 - val_loss: 1.2319 - val_accuracy: 0.5172\n",
            "Epoch 9/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.2339 - accuracy: 0.5205 - val_loss: 1.2296 - val_accuracy: 0.5170\n",
            "Epoch 10/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.2178 - accuracy: 0.5270 - val_loss: 1.2339 - val_accuracy: 0.5143\n",
            "Epoch 11/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.2039 - accuracy: 0.5321 - val_loss: 1.2109 - val_accuracy: 0.5329\n",
            "Epoch 12/75\n",
            "707/707 [==============================] - 9s 13ms/step - loss: 1.1882 - accuracy: 0.5406 - val_loss: 1.1948 - val_accuracy: 0.5313\n",
            "Epoch 13/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.1664 - accuracy: 0.5455 - val_loss: 1.1932 - val_accuracy: 0.5370\n",
            "Epoch 14/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.1494 - accuracy: 0.5529 - val_loss: 1.1859 - val_accuracy: 0.5430\n",
            "Epoch 15/75\n",
            "707/707 [==============================] - 9s 12ms/step - loss: 1.1438 - accuracy: 0.5592 - val_loss: 1.1792 - val_accuracy: 0.5472\n",
            "Epoch 16/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.1382 - accuracy: 0.5602 - val_loss: 1.1763 - val_accuracy: 0.5501\n",
            "Epoch 17/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.1184 - accuracy: 0.5674 - val_loss: 1.1830 - val_accuracy: 0.5400\n",
            "Epoch 18/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.1080 - accuracy: 0.5752 - val_loss: 1.1493 - val_accuracy: 0.5584\n",
            "Epoch 19/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.0988 - accuracy: 0.5788 - val_loss: 1.1659 - val_accuracy: 0.5552\n",
            "Epoch 20/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.0892 - accuracy: 0.5792 - val_loss: 1.1591 - val_accuracy: 0.5589\n",
            "Epoch 21/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.0753 - accuracy: 0.5849 - val_loss: 1.1726 - val_accuracy: 0.5527\n",
            "Epoch 22/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.0729 - accuracy: 0.5895 - val_loss: 1.1746 - val_accuracy: 0.5483\n",
            "Epoch 23/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.0647 - accuracy: 0.5869 - val_loss: 1.1413 - val_accuracy: 0.5707\n",
            "Epoch 24/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.0473 - accuracy: 0.6004 - val_loss: 1.1743 - val_accuracy: 0.5571\n",
            "Epoch 25/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.0440 - accuracy: 0.6031 - val_loss: 1.1467 - val_accuracy: 0.5614\n",
            "Epoch 26/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.0187 - accuracy: 0.6098 - val_loss: 1.1470 - val_accuracy: 0.5679\n",
            "Epoch 27/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.0297 - accuracy: 0.6063 - val_loss: 1.1425 - val_accuracy: 0.5661\n",
            "Epoch 28/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 1.0117 - accuracy: 0.6160 - val_loss: 1.1665 - val_accuracy: 0.5529\n",
            "Epoch 29/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 1.0084 - accuracy: 0.6128 - val_loss: 1.1397 - val_accuracy: 0.5679\n",
            "Epoch 30/75\n",
            "707/707 [==============================] - 9s 12ms/step - loss: 1.0059 - accuracy: 0.6141 - val_loss: 1.1363 - val_accuracy: 0.5684\n",
            "Epoch 31/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9921 - accuracy: 0.6193 - val_loss: 1.1428 - val_accuracy: 0.5704\n",
            "Epoch 32/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9872 - accuracy: 0.6216 - val_loss: 1.1565 - val_accuracy: 0.5610\n",
            "Epoch 33/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9707 - accuracy: 0.6275 - val_loss: 1.1421 - val_accuracy: 0.5654\n",
            "Epoch 34/75\n",
            "707/707 [==============================] - 9s 12ms/step - loss: 0.9667 - accuracy: 0.6328 - val_loss: 1.1444 - val_accuracy: 0.5707\n",
            "Epoch 35/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9619 - accuracy: 0.6345 - val_loss: 1.1724 - val_accuracy: 0.5585\n",
            "Epoch 36/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9548 - accuracy: 0.6340 - val_loss: 1.1400 - val_accuracy: 0.5709\n",
            "Epoch 37/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9477 - accuracy: 0.6386 - val_loss: 1.1385 - val_accuracy: 0.5700\n",
            "Epoch 38/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9450 - accuracy: 0.6443 - val_loss: 1.1393 - val_accuracy: 0.5704\n",
            "Epoch 39/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9302 - accuracy: 0.6449 - val_loss: 1.1564 - val_accuracy: 0.5692\n",
            "Epoch 40/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9252 - accuracy: 0.6489 - val_loss: 1.1410 - val_accuracy: 0.5707\n",
            "Epoch 41/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9378 - accuracy: 0.6426 - val_loss: 1.1484 - val_accuracy: 0.5729\n",
            "Epoch 42/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9160 - accuracy: 0.6487 - val_loss: 1.1380 - val_accuracy: 0.5755\n",
            "Epoch 43/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9158 - accuracy: 0.6554 - val_loss: 1.1461 - val_accuracy: 0.5745\n",
            "Epoch 44/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.9037 - accuracy: 0.6589 - val_loss: 1.1435 - val_accuracy: 0.5738\n",
            "Epoch 45/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9223 - accuracy: 0.6526 - val_loss: 1.1387 - val_accuracy: 0.5743\n",
            "Epoch 46/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8989 - accuracy: 0.6608 - val_loss: 1.1345 - val_accuracy: 0.5775\n",
            "Epoch 47/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.9061 - accuracy: 0.6577 - val_loss: 1.1322 - val_accuracy: 0.5732\n",
            "Epoch 48/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8908 - accuracy: 0.6635 - val_loss: 1.1326 - val_accuracy: 0.5761\n",
            "Epoch 49/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8882 - accuracy: 0.6665 - val_loss: 1.1434 - val_accuracy: 0.5762\n",
            "Epoch 50/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8741 - accuracy: 0.6719 - val_loss: 1.1262 - val_accuracy: 0.5773\n",
            "Epoch 51/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8721 - accuracy: 0.6694 - val_loss: 1.1547 - val_accuracy: 0.5667\n",
            "Epoch 52/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8704 - accuracy: 0.6703 - val_loss: 1.1304 - val_accuracy: 0.5895\n",
            "Epoch 53/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8561 - accuracy: 0.6763 - val_loss: 1.1335 - val_accuracy: 0.5854\n",
            "Epoch 54/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8681 - accuracy: 0.6729 - val_loss: 1.1410 - val_accuracy: 0.5730\n",
            "Epoch 55/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8598 - accuracy: 0.6747 - val_loss: 1.1437 - val_accuracy: 0.5739\n",
            "Epoch 56/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8540 - accuracy: 0.6745 - val_loss: 1.1418 - val_accuracy: 0.5837\n",
            "Epoch 57/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8560 - accuracy: 0.6789 - val_loss: 1.1368 - val_accuracy: 0.5807\n",
            "Epoch 58/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8593 - accuracy: 0.6768 - val_loss: 1.1248 - val_accuracy: 0.5893\n",
            "Epoch 59/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8385 - accuracy: 0.6842 - val_loss: 1.1417 - val_accuracy: 0.5753\n",
            "Epoch 60/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8468 - accuracy: 0.6822 - val_loss: 1.1428 - val_accuracy: 0.5814\n",
            "Epoch 61/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8375 - accuracy: 0.6868 - val_loss: 1.1803 - val_accuracy: 0.5573\n",
            "Epoch 62/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8331 - accuracy: 0.6839 - val_loss: 1.1410 - val_accuracy: 0.5858\n",
            "Epoch 63/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8247 - accuracy: 0.6898 - val_loss: 1.1365 - val_accuracy: 0.5893\n",
            "Epoch 64/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8156 - accuracy: 0.6926 - val_loss: 1.1302 - val_accuracy: 0.5883\n",
            "Epoch 65/75\n",
            "707/707 [==============================] - 8s 12ms/step - loss: 0.8187 - accuracy: 0.6903 - val_loss: 1.1503 - val_accuracy: 0.5741\n",
            "Epoch 66/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8158 - accuracy: 0.6903 - val_loss: 1.1312 - val_accuracy: 0.5798\n",
            "Epoch 67/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8166 - accuracy: 0.6935 - val_loss: 1.1358 - val_accuracy: 0.5803\n",
            "Epoch 68/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8065 - accuracy: 0.6963 - val_loss: 1.1407 - val_accuracy: 0.5812\n",
            "Epoch 69/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8085 - accuracy: 0.6964 - val_loss: 1.1404 - val_accuracy: 0.5815\n",
            "Epoch 70/75\n",
            "707/707 [==============================] - 7s 10ms/step - loss: 0.8072 - accuracy: 0.6974 - val_loss: 1.1441 - val_accuracy: 0.5845\n",
            "Epoch 71/75\n",
            "707/707 [==============================] - 8s 11ms/step - loss: 0.8135 - accuracy: 0.6944 - val_loss: 1.1492 - val_accuracy: 0.5844\n",
            "Epoch 72/75\n",
            "507/707 [====================>.........] - ETA: 1s - loss: 0.8043 - accuracy: 0.6974"
          ]
        }
      ],
      "source": [
        "best_model = None\n",
        "best_history = None\n",
        "best_accuracy = 0\n",
        "cnn_model, cnn_history = train_cnn('train', args)\n",
        "cnn_accuracy = max(cnn_history.history['val_accuracy'])\n",
        "print('validation accuracy:',cnn_accuracy)\n",
        "analyze_model('test',cnn_model,cnn_history)\n",
        "if cnn_accuracy > best_accuracy:\n",
        "    best_model = cnn_model\n",
        "    best_history = cnn_history\n",
        "    best_accuracy = cnn_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svXlUF7ZyE7A"
      },
      "outputs": [],
      "source": [
        "analyze_model('test',best_model,best_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RWnnzDryEsr"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
